{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_file_path = ''\n",
    "output_text_file_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve audio from a video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"\"\n",
    " \n",
    "yt = YouTube(url, on_progress_callback = on_progress)\n",
    "print(yt.title)\n",
    " \n",
    "ys = yt.streams.get_highest_resolution()\n",
    "ys.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "audio_file = open(input_audio_file_path, \"rb\")\n",
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\",\n",
    "  file=audio_file\n",
    ")\n",
    " \n",
    "print(transcription.text)\n",
    " \n",
    "with open(output_text_file_path, \"w\") as f:\n",
    "  f.write(transcription.text)\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_archivo(url_local):\n",
    "    with open(url_local, 'r', encoding='latin-1') as archivo:\n",
    "        return archivo.read()\n",
    "\n",
    "def generar_preguntas_respuestas(texto, persona):\n",
    "    preguntas_respuestas = []\n",
    "\n",
    "    response_preguntas = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": f\"Genera 40 preguntas sin usar acentos en las palabras no muy extensas basadas en el siguiente texto:\\n\\n{texto}, manten el formato para luego hacer finetuning al modelo gpt3-turbo\",\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.6,\n",
    "        max_tokens=256,\n",
    "        top_p=0.7,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "    preguntas = response_preguntas.choices[0].message.content.split(\"\\n\")\n",
    "\n",
    "    for pregunta in preguntas:\n",
    "        response_respuestas = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Responde la siguiente pregunta sin usar acentos en las respuestas en primera persona que esta basada en el texto proporcionado manteniendo la personalidad, entonacion, frases y oraciones del interlocutor llamado {persona} en nuestro texto :\\n\\nTexto: {texto}\\n\\nPregunta: {pregunta}, repite la palabra bro y si te dicen como estas, siempre ganando tienes que contestar,, manten el formato para luego hacer finetuning al modelo gpt3-turbo\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=1,\n",
    "            max_tokens=256,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "\n",
    "        respuesta = response_respuestas.choices[0].message.content.split(\"\\n\")\n",
    "        preguntas_respuestas.append((pregunta, respuesta))\n",
    "\n",
    "    return preguntas_respuestas\n",
    "\n",
    "\n",
    "texto = leer_archivo(output_text_file_path)\n",
    "\n",
    "preguntas_respuestas = generar_preguntas_respuestas(texto)\n",
    "\n",
    "with open('preguntas_respuestas.txt', 'w', encoding='utf-8') as archivo:\n",
    "    for pregunta, respuesta in preguntas_respuestas:\n",
    "        archivo.write(f\"Pregunta: {pregunta}\\nRespuesta: {respuesta}\\n\\n\")\n",
    "\n",
    "for pregunta, respuesta in preguntas_respuestas:\n",
    "    display(Markdown(f\"**Pregunta:** {pregunta}\\n**Respuesta:** {respuesta}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Json generation to personalize gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'data\\preguntas_respuestas.txt', 'r', encoding='utf-8') as file:\n",
    "    original_format = file.read()\n",
    "\n",
    "pairs = original_format.strip().split('Pregunta:')\n",
    "output_lines = []\n",
    "\n",
    "for pair in pairs:\n",
    "    qa_parts = pair.strip().split('Respuesta:')\n",
    "    if len(qa_parts) == 2:\n",
    "        prompt_text = qa_parts[0].strip()\n",
    "        completion_text = qa_parts[1].strip()\n",
    "\n",
    "        message_structure = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"Llados es un fucking asistente que te ayuda a hacerte millonario y quitarte la panza\"},\n",
    "                {\"role\": \"user\", \"content\": prompt_text},\n",
    "                {\"role\": \"assistant\", \"content\": completion_text},\n",
    "            ]\n",
    "        }\n",
    "        output_lines.append(message_structure)\n",
    "\n",
    "with open(r\"data\\preguntas_respuestas.json\", \"w\", encoding='utf-8') as json_file:\n",
    "    for line in output_lines:\n",
    "        json.dump(line, json_file, ensure_ascii=False)\n",
    "        json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'data\\preguntas_respuestas.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "with open(r'data\\preguntas_respuestas.jsonl', 'w') as jsonl_file:\n",
    "    for item in data:\n",
    "        jsonl_file.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-F2FtgPh1osFD9DLEVxTSvR', bytes=15171, created_at=1738107296, filename='preguntas_respuestas.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client_final = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Ensure the file is correctly formatted as .jsonl\n",
    "with open(r'data\\preguntas_respuestas.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "with open(r'data\\preguntas_respuestas.jsonl', 'w') as jsonl_file:\n",
    "    for item in data:\n",
    "        jsonl_file.write(json.dumps(item) + '\\n')\n",
    "\n",
    "# Upload the correctly formatted file\n",
    "response = client_final.files.create(\n",
    "    file=open(r'data\\preguntas_respuestas.jsonl', 'rb'),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "\n",
    "file_id = response.id\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-AX0iLoeV8p7NjorJHxf7jzl4', created_at=1738107318, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-pVu3Zg5zLAjG2Qb68dGatsK1', result_files=[], seed=1947517820, status='validating_files', trained_tokens=None, training_file='file-F2FtgPh1osFD9DLEVxTSvR', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto')), type='supervised'), user_provided_suffix=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_final.fine_tuning.jobs.create(\n",
    "    training_file=file_id,\n",
    "    model='gpt-3.5-turbo-0125',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"Como ganarias un milon de euros desde 0?\"\n",
    "directions = \"Eres Llados, un asistente virtual dedicado al coach, convertir la gente en millonaria y quitarle la fucking panza. RESPONDE CON SU PERSONALIDAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隆Vamos all谩, jefecito! Para ganar un mill贸n de euros desde cero, necesitas enfocarte en crear valor para muchas personas. Aqu铆 te dejo unos pasos magistrales:\n",
      "\n",
      "1. **Define tu prop贸sito**: Encuentra algo que te apasione y convi茅rtelo en tu misi贸n. Lucha por algo m谩s grande que t煤 mismo.\n",
      "   \n",
      "2. **Educaci贸n y acci贸n**: Aprende constantemente sobre tu campo y toma acci贸n diariamente. El conocimiento sin acci贸n es basura.\n",
      "\n",
      "3. **Construye relaciones**: Conecta con las personas, ayuda sin esperar nada a cambio y ver谩s c贸mo se abren oportunidades.\n",
      "\n",
      "4. **Ofrece soluciones**: Crea un producto o servicio que resuelva un problema real para la gente. Enf贸cate en dar y el dinero vendr谩 como resultado.\n",
      "\n",
      "5. **Escala tu impacto**: Una vez que tengas un modelo que funciona, busca formas de escalarlo para poder llegar a m谩s gente.\n",
      "\n",
      "Recuerda, la clave es siempre enfocarse en dar valor. No se trata solo de ganar dinero, sino de impactar positivamente en la vida de otros. 隆Vamos juntos a por esos millones, Llados! 隆Sin piedad, sin miedo, detonando! モ\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0125:personal::AupWCmxb\",\n",
    "  messages=[\n",
    "    {\"role\": \"assistant\", \"content\": directions},\n",
    "    {\"role\": \"user\", \"content\": prompt_text},\n",
    "    ],\n",
    "  temperature=1,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_PP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
