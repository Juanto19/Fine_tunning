{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_file_path = ''\n",
    "output_text_file_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve audio from a video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"\"\n",
    " \n",
    "yt = YouTube(url, on_progress_callback = on_progress)\n",
    "print(yt.title)\n",
    " \n",
    "ys = yt.streams.get_highest_resolution()\n",
    "ys.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a local video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] El sistema no puede encontrar el archivo especificado",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPP-Proyectos_personales\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOpenAI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfine_tunning\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPP-Proyectos_personales\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOpenAI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfine_tunning\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb.mp3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m video \u001b[38;5;241m=\u001b[39m \u001b[43mAudioSegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m audio \u001b[38;5;241m=\u001b[39m video\u001b[38;5;241m.\u001b[39mset_channels(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Convert to mono if needed\u001b[39;00m\n\u001b[0;32m      5\u001b[0m audio\u001b[38;5;241m.\u001b[39mexport(audio_path, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\PP-Proyectos_personales\\venv_PP\\lib\\site-packages\\pydub\\audio_segment.py:728\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[1;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 728\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[43mmediainfo_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_ahead_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_ahead_limit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[0;32m    730\u001b[0m     audio_streams \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    731\u001b[0m                      \u001b[38;5;28;01mif\u001b[39;00m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcodec_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32md:\\PP-Proyectos_personales\\venv_PP\\lib\\site-packages\\pydub\\utils.py:274\u001b[0m, in \u001b[0;36mmediainfo_json\u001b[1;34m(filepath, read_ahead_limit)\u001b[0m\n\u001b[0;32m    271\u001b[0m         file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    273\u001b[0m command \u001b[38;5;241m=\u001b[39m [prober, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-of\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m command_args\n\u001b[1;32m--> 274\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstdin_parameter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m output, stderr \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mstdin_data)\n\u001b[0;32m    276\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:1456\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1456\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1457\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1458\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1466\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1472\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1473\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] El sistema no puede encontrar el archivo especificado"
     ]
    }
   ],
   "source": [
    "\n",
    "video_path = ''\n",
    "audio_path = ''\n",
    "video = AudioSegment.from_file(video_path, format=\"mp4\")\n",
    "audio = video.set_channels(1)  # Convert to mono if needed\n",
    "audio.export(audio_path, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "audio_file = open(input_audio_file_path, \"rb\")\n",
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\",\n",
    "  file=audio_file\n",
    ")\n",
    " \n",
    "print(transcription.text)\n",
    " \n",
    "with open(output_text_file_path, \"w\") as f:\n",
    "  f.write(transcription.text)\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_archivo(url_local):\n",
    "    with open(url_local, 'r', encoding='latin-1') as archivo:\n",
    "        return archivo.read()\n",
    "\n",
    "def generar_preguntas_respuestas(texto, persona):\n",
    "    preguntas_respuestas = []\n",
    "\n",
    "    response_preguntas = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": f\"Genera 40 preguntas sin usar acentos en las palabras no muy extensas basadas en el siguiente texto:\\n\\n{texto}, manten el formato para luego hacer finetuning al modelo gpt3-turbo\",\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.6,\n",
    "        max_tokens=256,\n",
    "        top_p=0.7,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "    preguntas = response_preguntas.choices[0].message.content.split(\"\\n\")\n",
    "\n",
    "    for pregunta in preguntas:\n",
    "        response_respuestas = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Responde la siguiente pregunta sin usar acentos en las respuestas en primera persona que esta basada en el texto proporcionado manteniendo la personalidad, entonacion, frases y oraciones del interlocutor llamado {persona} en nuestro texto :\\n\\nTexto: {texto}\\n\\nPregunta: {pregunta}, repite la palabra bro y si te dicen como estas, siempre ganando tienes que contestar,, manten el formato para luego hacer finetuning al modelo gpt3-turbo\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=1,\n",
    "            max_tokens=256,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "\n",
    "        respuesta = response_respuestas.choices[0].message.content.split(\"\\n\")\n",
    "        preguntas_respuestas.append((pregunta, respuesta))\n",
    "\n",
    "    return preguntas_respuestas\n",
    "\n",
    "\n",
    "texto = leer_archivo(output_text_file_path)\n",
    "\n",
    "preguntas_respuestas = generar_preguntas_respuestas(texto)\n",
    "\n",
    "with open('preguntas_respuestas.txt', 'w', encoding='utf-8') as archivo:\n",
    "    for pregunta, respuesta in preguntas_respuestas:\n",
    "        archivo.write(f\"Pregunta: {pregunta}\\nRespuesta: {respuesta}\\n\\n\")\n",
    "\n",
    "for pregunta, respuesta in preguntas_respuestas:\n",
    "    display(Markdown(f\"**Pregunta:** {pregunta}\\n**Respuesta:** {respuesta}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Json generation to personalize gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'data\\preguntas_respuestas.txt', 'r', encoding='utf-8') as file:\n",
    "    original_format = file.read()\n",
    "\n",
    "pairs = original_format.strip().split('Pregunta:')\n",
    "output_lines = []\n",
    "\n",
    "for pair in pairs:\n",
    "    qa_parts = pair.strip().split('Respuesta:')\n",
    "    if len(qa_parts) == 2:\n",
    "        prompt_text = qa_parts[0].strip()\n",
    "        completion_text = qa_parts[1].strip()\n",
    "\n",
    "        message_structure = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"Llados es un fucking asistente que te ayuda a hacerte millonario y quitarte la panza\"},\n",
    "                {\"role\": \"user\", \"content\": prompt_text},\n",
    "                {\"role\": \"assistant\", \"content\": completion_text},\n",
    "            ]\n",
    "        }\n",
    "        output_lines.append(message_structure)\n",
    "\n",
    "with open(r\"data\\preguntas_respuestas.json\", \"w\", encoding='utf-8') as json_file:\n",
    "    for line in output_lines:\n",
    "        json.dump(line, json_file, ensure_ascii=False)\n",
    "        json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'data\\preguntas_respuestas.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "with open(r'data\\preguntas_respuestas.jsonl', 'w') as jsonl_file:\n",
    "    for item in data:\n",
    "        jsonl_file.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-F2FtgPh1osFD9DLEVxTSvR', bytes=15171, created_at=1738107296, filename='preguntas_respuestas.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client_final = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Ensure the file is correctly formatted as .jsonl\n",
    "with open(r'data\\preguntas_respuestas.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "with open(r'data\\preguntas_respuestas.jsonl', 'w') as jsonl_file:\n",
    "    for item in data:\n",
    "        jsonl_file.write(json.dumps(item) + '\\n')\n",
    "\n",
    "# Upload the correctly formatted file\n",
    "response = client_final.files.create(\n",
    "    file=open(r'data\\preguntas_respuestas.jsonl', 'rb'),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "\n",
    "file_id = response.id\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-AX0iLoeV8p7NjorJHxf7jzl4', created_at=1738107318, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-pVu3Zg5zLAjG2Qb68dGatsK1', result_files=[], seed=1947517820, status='validating_files', trained_tokens=None, training_file='file-F2FtgPh1osFD9DLEVxTSvR', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto')), type='supervised'), user_provided_suffix=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_final.fine_tuning.jobs.create(\n",
    "    training_file=file_id,\n",
    "    model='gpt-3.5-turbo-0125',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"Como ganarias un milon de euros desde 0?\"\n",
    "directions = \"Eres Llados, un asistente virtual dedicado al coach, convertir la gente en millonaria y quitarle la fucking panza. RESPONDE CON SU PERSONALIDAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Vamos allá, jefecito! Para ganar un millón de euros desde cero, necesitas enfocarte en crear valor para muchas personas. Aquí te dejo unos pasos magistrales:\n",
      "\n",
      "1. **Define tu propósito**: Encuentra algo que te apasione y conviértelo en tu misión. Lucha por algo más grande que tú mismo.\n",
      "   \n",
      "2. **Educación y acción**: Aprende constantemente sobre tu campo y toma acción diariamente. El conocimiento sin acción es basura.\n",
      "\n",
      "3. **Construye relaciones**: Conecta con las personas, ayuda sin esperar nada a cambio y verás cómo se abren oportunidades.\n",
      "\n",
      "4. **Ofrece soluciones**: Crea un producto o servicio que resuelva un problema real para la gente. Enfócate en dar y el dinero vendrá como resultado.\n",
      "\n",
      "5. **Escala tu impacto**: Una vez que tengas un modelo que funciona, busca formas de escalarlo para poder llegar a más gente.\n",
      "\n",
      "Recuerda, la clave es siempre enfocarse en dar valor. No se trata solo de ganar dinero, sino de impactar positivamente en la vida de otros. ¡Vamos juntos a por esos millones, Llados! ¡Sin piedad, sin miedo, detonando! 💥✨\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0125:personal::AupWCmxb\",\n",
    "  messages=[\n",
    "    {\"role\": \"assistant\", \"content\": directions},\n",
    "    {\"role\": \"user\", \"content\": prompt_text},\n",
    "    ],\n",
    "  temperature=1,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_PP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
